{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79b034d7-8d9e-4b16-90fb-7f066fb281ff",
   "metadata": {},
   "source": [
    "# Step 1: Load the Dataset\n",
    "First, let's load the dataset from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cb82df-0f89-4a88-a038-1d66aed44a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'winequality-white.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c07d23-cbe6-4f89-850b-1c21dd3d18f5",
   "metadata": {},
   "source": [
    "# Step 2: Prepare the Dataset\n",
    "Prepare the data for modeling by separating features and target variables and splitting into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147b8fb4-1e99-4238-9ed4-81098ded2d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = data.drop('quality', axis=1)\n",
    "y = data['quality']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d9d0f9-29ac-4fbe-9bda-e19ad74f9a09",
   "metadata": {},
   "source": [
    "# Step 3: Train MLPClassifier Models\n",
    "Train three different MLPClassifier models with different architectures and report the validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc22932a-7ce3-4820-8dbb-7b995a7b6ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model 1 - Mean CV Accuracy: 0.4872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model 2 - Mean CV Accuracy: 0.5265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Model 3 - Mean CV Accuracy: 0.5120\n",
      "Best MLP Model: mlp_2 with Accuracy: 0.5265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Define different MLP architectures\n",
    "mlp_1 = MLPClassifier(hidden_layer_sizes=(50,), activation='relu', random_state=42)\n",
    "mlp_2 = MLPClassifier(hidden_layer_sizes=(100, 50), activation='tanh', random_state=42)\n",
    "mlp_3 = MLPClassifier(hidden_layer_sizes=(100, 50, 25), activation='logistic', random_state=42)\n",
    "\n",
    "# Train and evaluate the models using cross-validation\n",
    "mlp_models = [mlp_1, mlp_2, mlp_3]\n",
    "mlp_scores = {}\n",
    "\n",
    "for i, mlp in enumerate(mlp_models, 1):\n",
    "    scores = cross_val_score(mlp, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    mlp_scores[f'mlp_{i}'] = scores.mean()\n",
    "    print(f'MLP Model {i} - Mean CV Accuracy: {scores.mean():.4f}')\n",
    "\n",
    "best_model_index = max(mlp_scores, key=mlp_scores.get)\n",
    "print(f'Best MLP Model: {best_model_index} with Accuracy: {mlp_scores[best_model_index]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbaf4fd-5141-422f-b5fa-2b2bf36d007b",
   "metadata": {},
   "source": [
    "* Best Model: MLP Model 2 with two hidden layers (100 and 50 neurons) and tanh activation function.\n",
    "* Validation Scoring Method: Accuracy was used to evaluate model performance, with cross-validation to ensure the reliability of the results.\n",
    "* Convergence Issues: All models reached the maximum number of iterations without converging, indicating a need for further tuning (e.g., increasing the number of iterations or adjusting learning rates)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd4a63-8fa2-4c5c-8ac6-8e33b0636783",
   "metadata": {},
   "source": [
    "# Step 4: Hyperparameter Tuning on the Best Model\n",
    "Pick the best-performing model and study the impact of varying three hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b79d4b-3fa8-42a8-9493-a2b66adf32ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate_init': 0.001, 'max_iter': 300, 'solver': 'adam'}\n",
      "Best CV Accuracy: 0.5291\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Best performing model (replace mlp_X with the actual best model from previous step)\n",
    "best_mlp = mlp_models[int(best_model_index.split('_')[1]) - 1]\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [200, 300, 400]\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(best_mlp, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Report the best parameters and the corresponding score\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Best CV Accuracy: {grid_search.best_score_:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed62435c-d77a-40f1-a596-d06ad9f5533e",
   "metadata": {},
   "source": [
    "**Validation Scoring Method**\n",
    "\n",
    "The validation scoring method used was accuracy, which measures the proportion of correctly predicted instances out of the total instances. Accuracy is a straightforward and widely used metric for classification problems.\n",
    "\n",
    "**MLP Model 2 Performance**\n",
    "\n",
    "* Initial Performance: MLP Model 2 had a mean cross-validation accuracy of 0.5265, indicating it was the best among the three architectures tested.\n",
    "* Hyperparameter Tuning: After tuning, the best parameters improved the mean cross-validation accuracy to 0.5291. The adam solver, learning_rate_init of 0.001, and max_iter of 300 were found to be the optimal settings.\n",
    "\n",
    "**Convergence Issues**\n",
    "\n",
    "All models reached the maximum number of iterations without converging, as indicated by the convergence warnings. This suggests that further adjustments, such as increasing the number of iterations, adjusting the learning rates, or exploring other optimizers, could potentially improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eed16dd-7c20-4434-9978-6a9687a904fd",
   "metadata": {},
   "source": [
    "# Step 5: Evaluate the Best Model with Different Scoring Methods\n",
    "Test the best model's performance using different scoring methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996d1854-d305-4429-9ced-f9077786d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5490\n",
      "Test Precision: 0.5419\n",
      "Test Recall: 0.5490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Get the best model from the grid search\n",
    "best_mlp_tuned = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_mlp_tuned.predict(X_test)\n",
    "\n",
    "# Evaluate using different scoring methods\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "print(f'Test Precision: {precision:.4f}')\n",
    "print(f'Test Recall: {recall:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d580e-7eb1-4d5d-8396-9bfda3cb9267",
   "metadata": {},
   "source": [
    "The performance of the best-tuned MLP model on the test set suggests that the model has room for improvement. The test accuracy of 54.90% indicates that the model is only slightly better than a random guess for this multi-class classification problem (assuming 10 classes, a random guess would have an accuracy of about 10%).\n",
    "\n",
    "__Cross-Validation and Test Performance Comparison__\n",
    "* Cross-Validation Accuracy: The best cross-validation accuracy during hyperparameter tuning was 0.5291.\n",
    "* Test Accuracy: The test accuracy is 0.5490.\n",
    "The similar performance between cross-validation accuracy (0.5291) and test accuracy (0.5490) suggests that the model is not significantly overfitting. However, both scores indicate relatively low performance, which might suggest some degree of underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17945831-ee3e-459a-84ee-c36943c03cc0",
   "metadata": {},
   "source": [
    "# Step 6: Train and Evaluate a Classical ML Model\n",
    "Train a new classifier that is not a neural network and compare its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "704fada5-ec55-4e40-af1e-cf5ee4be12f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Test Accuracy: 0.6796\n",
      "Random Forest - Test Precision: 0.6882\n",
      "Random Forest - Test Recall: 0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/project/dsi/apps/anaconda3/python-3.10/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define and train a RandomForestClassifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate using different scoring methods\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "print(f'Random Forest - Test Accuracy: {accuracy_rf:.4f}')\n",
    "print(f'Random Forest - Test Precision: {precision_rf:.4f}')\n",
    "print(f'Random Forest - Test Recall: {recall_rf:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442e62b3-779f-4b76-8771-c80d7ed14480",
   "metadata": {},
   "source": [
    "* Model Comparison: The Random Forest classifier outperforms the MLP classifier in all three metrics: accuracy, precision, and recall. The Random Forest model's accuracy and recall are significantly higher, indicating that it better captures the underlying patterns in the data and makes more accurate predictions. Additionally, the higher precision of the Random Forest model means that it makes more reliable positive predictions.\n",
    "* Potential Issues with MLP: The relatively low performance of the MLP model suggests potential issues such as underfitting, as indicated by the similar cross-validation and test accuracy scores. The convergence warnings also suggest that the MLP model might require further tuning, such as increasing the number of iterations or adjusting the learning rates.\n",
    "* Recommendation: Based on these results, the Random Forest classifier is recommended for predicting wine quality in this dataset. Further tuning and optimization of the MLP model might be necessary to improve its performance, but the Random Forest model provides a more accurate and reliable baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9dd6c8-a27e-40cf-a7cb-17a36a027112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
