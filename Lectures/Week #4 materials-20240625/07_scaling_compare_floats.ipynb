{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Pandas for data handling\n",
    "import pandas # https://pandas.pydata.org/\n",
    "# from pandas.plotting import scatter_matrix\n",
    "\n",
    "# pretty tables\n",
    "from IPython.display import display\n",
    "\n",
    "# NumPy for numerical computing\n",
    "import numpy # https://numpy.org/\n",
    "\n",
    "# MatPlotLib+Seaborn for visualization\n",
    "import matplotlib.pyplot as pl  # https://matplotlib.org/\n",
    "import seaborn as sns\n",
    "\n",
    "# assessment\n",
    "from sklearn import model_selection # for model comparisons\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "# algorithms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# data preprocessing / feature selection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# combining\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "#########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data from file ...')  # Now let's load the data\n",
    "dataset = pandas.read_csv('floats.csv') # default is header=infer, change if column names are not in first row\n",
    "print('done \\n')\n",
    "\n",
    "print('Removing rows with missing data ...')  # Make things simple\n",
    "dataset = dataset.dropna()  # default is to drop any row that contains at least one missing value\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up a problem: Can we predict 'callSign' using these three features: 'Depth', 'Temperature', 'Salinity' ?\n",
    "\n",
    "print('Reading list of problem variables X and Y...')\n",
    "X_name = [ 'Depth', 'Temperature', 'Salinity' ] # columns to focus on as predictors\n",
    "X = dataset[X_name]   # only keep these columns as features\n",
    "y_name = 'callSign'     # column to focus on as target\n",
    "y = dataset[y_name]   # only keep this column as label \n",
    "print('done \\n')\n",
    "\n",
    "# Split-out test dataset\n",
    "\n",
    "# We reset the random number seed before each run to ensure that the evaluation of each algorithm is performed using exactly the same data splits. It ensures the results are directly comparable.\n",
    "seed = 42\n",
    "\n",
    "# Train, test split\n",
    "print('Partitioning data into parts: formative (for development) and summative (for testing) ...')\n",
    "test_size = 0.20   # means 20 percent\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA\n",
    "\n",
    "display(X_train.describe(include='all'))\n",
    "X_train.hist(figsize=(15, 15), bins=12)  # bins ~= sqrt(N)\n",
    "pl.show()\n",
    "\n",
    "display(y_train.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the formative scoring method\n",
    "\n",
    "print('Reading list of scoring methods to use during model development ...')\n",
    "scoring = 'accuracy'\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the Algorithms\n",
    "\n",
    "seed = 42 # setting the seed allows for repeatability\n",
    "\n",
    "print('Reading list of algorithms to train ...')\n",
    "models = []\n",
    "models.append(( 'raw_SVM', SVC(random_state=seed) ))\n",
    "models.append(( 'scaled_SVM', make_pipeline( MinMaxScaler(), SVC(random_state=seed) )  ))\n",
    "models.append(( 'raw_kNN', KNeighborsClassifier() ))\n",
    "models.append(( 'scaled_kNN', make_pipeline( MinMaxScaler(), KNeighborsClassifier() )  ))\n",
    "models.append(( 'raw_DT', DecisionTreeClassifier(random_state=seed) ))\n",
    "models.append(( 'scaled_DT', make_pipeline( MinMaxScaler(), DecisionTreeClassifier(random_state=seed) )  ))\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it is time to train some models on the data and estimate their accuracy on unseen data.\n",
    "\n",
    "k4folds = 5\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:   # Select each model in turn\n",
    "    print(\" ++ NOW WORKING ON ALGORITHM %s ++\" % name)\n",
    "    print(\"Splitting data into %s folds\" % k4folds)\n",
    "    kfold = model_selection.KFold(n_splits=k4folds, random_state=seed, shuffle=True)\n",
    "    print(\"Training model on each split ...\")\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring, verbose=3)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"algorithm %s %s results: mean = %f (std = %f)\" % (name, scoring, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = pl.figure(figsize=(15,5))\n",
    "fig.suptitle('Algorithm Comparison based on %s' % scoring)\n",
    "ax = fig.add_subplot(111)\n",
    "pl.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test dataset\n",
    "selected_model = make_pipeline( MinMaxScaler(),KNeighborsClassifier() ) \n",
    "selected_model.fit(X_train, y_train)\n",
    "predictions = selected_model.predict(X_test)\n",
    "print(\" ++++ Detailed classification report for the selected model ++++ \" )\n",
    "print(\"Algorithm: %s \" % selected_model)\n",
    "print(\"This model was trained and tuned on the development set using CV.\")\n",
    "print(\"The following results are computed on the separate test set:\")\n",
    "#\n",
    "predictions = selected_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "df_cm = pandas.DataFrame(cm, columns=numpy.unique(y_test), index = numpy.unique(y_test))\n",
    "sns.heatmap(df_cm, square=True, annot=True, fmt='d', cbar=False )\n",
    "pl.xlabel('predicted')\n",
    "pl.ylabel('true')\n",
    "pl.show()\n",
    "#\n",
    "print('\\n clasification report:\\n', classification_report(y_test, predictions))\n",
    "print('Cohen Kappa Score:', cohen_kappa_score(y_test, predictions))\n",
    "print('\\n')        \n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
