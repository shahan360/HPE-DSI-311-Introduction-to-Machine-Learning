{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# First, letâ€™s import all of the modules, functions and objects we are going to use in this tutorial.\n",
    "\n",
    "# Pandas for data handling\n",
    "import pandas # https://pandas.pydata.org/\n",
    "\n",
    "# NumPy for numerical computing\n",
    "import numpy # https://numpy.org/\n",
    "\n",
    "# MatPlotLib for visualization\n",
    "import matplotlib.pyplot as pl  # https://matplotlib.org/\n",
    "\n",
    "# assessment\n",
    "from sklearn import model_selection # for model comparisons\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# algorithms\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data...')  # Now let's load the data\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.keys()\n",
    "\n",
    "# let's plot to see what the data looks like\n",
    "fig = pl.figure(figsize=(6, 6))  # figure size in inches\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "# plot the digits: each image is 8x8 pixels\n",
    "for i in range(64):\n",
    "    ax = fig.add_subplot(8, 8, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(digits.images[i], cmap=pl.cm.binary, interpolation='nearest')\n",
    "    \n",
    "    # label the image with the target value\n",
    "    ax.text(0, 7, str(digits.target[i]))\n",
    "    \n",
    "    \n",
    "# Test dataset is already split from the rest\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=42)\n",
    "\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll focus on accuracy as both formative and summative scoring method\n",
    "scoring = 'f1_macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it is time to tune some models on the training data and estimate their accuracy on unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k Nearest Neighbors\n",
    "print('Tuning model...')\n",
    "selected_model = KNeighborsClassifier()\n",
    "hyperparameters = {'n_neighbors':[4, 5, 6], 'weights':['uniform', 'distance'] }\n",
    "clf = GridSearchCV(selected_model, hyperparameters, cv=5, scoring=scoring)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters found on development set for k Nearest Neighbors:\")\n",
    "print(clf.best_params_)\n",
    "tuned_model_kNN = clf.best_estimator_\n",
    "\n",
    "y_pred = tuned_model_kNN.predict(X_test)\n",
    "print( 'f1_score is')\n",
    "print( f1_score(y_test, y_pred, average='macro') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "print('Tuning model...')\n",
    "selected_model = DecisionTreeClassifier()\n",
    "hyperparameters = {'max_depth':[5, 6, 7], 'criterion':['gini', 'entropy'] }\n",
    "clf = GridSearchCV(selected_model, hyperparameters, cv=5, scoring=scoring)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters found on development set for Decision Tree:\")\n",
    "print(clf.best_params_)\n",
    "tuned_model_DT = clf.best_estimator_\n",
    "\n",
    "print(f'Decision tree has maximum depth {tuned_model_DT.tree_.max_depth}.')\n",
    "y_pred = tuned_model_DT.predict(X_test)\n",
    "print( 'f1_score is')\n",
    "print( f1_score(y_test, y_pred, average='macro') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "print('Tuning model...')\n",
    "selected_model = RandomForestClassifier()\n",
    "hyperparameters = {'max_depth':[3, 4, 5], 'criterion':['gini', 'entropy'], 'n_estimators':[10, 50, 100] }\n",
    "clf = GridSearchCV(selected_model, hyperparameters, cv=4, scoring=scoring,  verbose=2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters found on development set for Random Forest:\")\n",
    "print(clf.best_params_)\n",
    "tuned_model_RF = clf.best_estimator_\n",
    "\n",
    "y_pred = tuned_model_RF.predict(X_test)\n",
    "print( 'f1_score is')\n",
    "print( f1_score(y_test, y_pred, average='macro') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "print('Tuning model...')\n",
    "selected_model = HistGradientBoostingClassifier()\n",
    "hyperparameters = {'max_depth':[3, 4, 5] }\n",
    "clf = GridSearchCV(selected_model, hyperparameters, cv=4, scoring=scoring, verbose=2)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Best hyperparameters found on development set for Gradient Boosting:\")\n",
    "print(clf.best_params_)\n",
    "tuned_model_GB = clf.best_estimator_\n",
    "\n",
    "y_pred = tuned_model_GB.predict(X_test)\n",
    "print( 'f1_score is')\n",
    "print( f1_score(y_test, y_pred, average='macro') )\n",
    "\n",
    "print('done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
